{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Please wait for the installation to be done before proceeding.\n",
    "! pip install --quiet --requirement requirements.txt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055e230b-be5b-481a-aef2-ad6e81675197",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b05636f-bc3b-433f-8d22-4fd60d77e7fa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.figsize'] = (12, 10)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file = tf.keras.utils\n",
    "raw_df = pd.read_csv('https://storage.googleapis.com/download.tensorflow.org/data/creditcard.csv')\n",
    "raw_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c75bf12-1c60-42a8-b1f4-369e66a26800",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "raw_df[['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V26', 'V27', 'V28', 'Amount', 'Class']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eb4b0c-a9a2-48c8-ada5-b3c4dd763c70",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "data=raw_df\n",
    "#Rename Class\n",
    "data.rename(columns={\"Class\": \"isFraud\"}, inplace=True)\n",
    "\n",
    "#Percentage of fraud\n",
    "fraud_per = data[data.isFraud == 1].isFraud.count() / data.isFraud.count()\n",
    "print(fraud_per)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9b5155-305c-400f-b2c2-ce0ecd8ca711",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Looking for missing data\n",
    "print(data.isnull().any().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4cf6c9-c621-441e-b73c-983cfd20df6f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#Correlation Plot\n",
    "plt.figure(figsize = (14,10))\n",
    "plt.title('Correlation Plot', size = 20)\n",
    "corr = data.corr()\n",
    "sns.heatmap(corr,xticklabels=corr.columns,yticklabels=corr.columns,linewidths=.1,cmap=\"Blues\",fmt='.1f',annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "940903bd-0d9a-47f8-8fc0-7cb3b6277df6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Defining x and y\n",
    "y = data[\"isFraud\"]\n",
    "x = data.drop([\"isFraud\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ae56f38-aaf3-407b-9c8b-24b0544f7563",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Standardization\n",
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c2fd2db-336a-4a8d-9d6b-7e056026df7b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Train-Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0601047-e2ea-43f5-9b90-1bfc633b0b00",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# SMOTE\n",
    "X_train_SMOTE, y_train_SMOTE = SMOTE().fit_resample(X_train, y_train)\n",
    "#SMOTE plot\n",
    "pd.Series(y_train_SMOTE).value_counts().plot(kind=\"bar\")\n",
    "plt.title(\"Balanced Dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60a7f89-bd53-4429-b434-6e7722f0d3ce",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# DNN\n",
    "layers = keras.layers\n",
    "model = keras.Sequential([\n",
    "layers.Dense(input_dim = 30, units = 128, activation = \"relu\"),\n",
    "layers.Dense(units= 64, activation = \"relu\"),\n",
    "layers.Dropout(0.2),\n",
    "layers.Dense(units= 32, activation = \"relu\"),\n",
    "layers.Dropout(0.2),\n",
    "layers.Dense(units= 32, activation = \"relu\"),\n",
    "layers.Dropout(0.2),\n",
    "layers.Dense(units= 16, activation = \"relu\"),\n",
    "layers.Dropout(0.2),\n",
    "layers.Dense(units=1, activation = \"sigmoid\")])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c6530e-0ce6-4858-9c48-0c276823a25a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Metrics\n",
    "metrics = [\n",
    "    keras.metrics.Accuracy(name=\"Accuracy\"),\n",
    "    keras.metrics.Precision(name=\"Precision\"),\n",
    "    keras.metrics.Recall(name=\"Recall\")]\n",
    "# Compiling and fiting the model\n",
    "model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = metrics)\n",
    "# Change the epochs to a lower number if you want this to run quickly. But lower epoch is less accuracy and vice versa.\n",
    "model.fit(X_train_SMOTE, y_train_SMOTE, batch_size = 32, epochs = 100)\n",
    "print(\"Evaluate on test data\")\n",
    "score = model.evaluate(X_test, y_test)\n",
    "print(\"test loss, test accuracy, test precision, test recall:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Our model is trained. Lets save it to disk and then convert to openvino ir format.\n",
    "# Change the model_name variable when you want to preserve multiple models in different folders\n",
    "model_name = \"default\"\n",
    "model.save('tensorflow_pb_models/' + model_name)\n",
    "\n",
    "# Model Optimizer (mo) helps to convert tensorflow protobuf (.pb) file to openvino supported formate.\n",
    "# https://docs.openvino.ai/latest/openvino_docs_MO_DG_Deep_Learning_Model_Optimizer_DevGuide.html\n",
    "! mo --output_dir openvino_ir_model/{model_name} --saved_model_dir tensorflow_pb_models/{model_name}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Upload the openvino IR formatted model to your S3 bucket. Follow [guide](./upload-to-s3-and-serve-model.md)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212f936b-f855-4731-a728-c13509750368",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# ## YOU MUST PASTE YOUR INFERENCE LINK GOT AS AN OUTCOME OF THE ABOVE GUIDE LINK\n",
    "my_route = 'https://PASTE-YOUR-OWN-INFER-LINK'\n",
    "\n",
    "import requests, json\n",
    "my_req = '{\"inputs\": [{\"name\":\"Func/StatefulPartitionedCall/input/_0:0\", \"shape\": [1,30], \"datatype\": \"FP32\", \"data\": [[-0.81527562, -0.62780094,  1.18457726, -0.56138278,  1.97545981, -1.38669424, -0.03372776, -1.08378356, -0.46514641, -1.07813139, -2.98031409,  2.29087639, -2.82230106, 0.76695155, -5.65368683, 0.04526619, -4.77118557, -5.04520325, -3.02616084,  1.14274513, 0.35082495,  1.64467922,  0.38254332,  0.03085198, 0.83964697, -0.38594229, -0.51760032,  1.39294962,  0.22815041, 0.3301235]]}]}'\n",
    "\n",
    "response = requests.post(my_route, my_req)\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ----------------------------------------------------------------------------------------------------------------------------------------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Below cells are some extra bonus/fun stuff.\n",
    "# Converting X_test array to numpy array before predicting\n",
    "pred = model.predict(np.array(X_test))\n",
    "pred = np.where(pred > 0.5, 1, 0)\n",
    "pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fd89f5-443b-45d9-adc6-609f17ed1c65",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Checking accuracy of the prediction by the model.\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66ddcb3-01b5-4b71-b106-9f9766f047bd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Because it was an imbalanced dataset and the SMOTE technique was applied to training set and\n",
    "# not testing set therefore the above accuracy is not correct but the f1 score below gives a better accuracy.\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test, pred, zero_division=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ece81c-e113-4af6-8c32-cde9967e9829",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# The confusionmatrix and the plotting shows how many wrong prediction our model did because it is not perfect.\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['non fraud', 'fraud'])\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}