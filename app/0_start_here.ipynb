{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running an application\n",
    "\n",
    "Now that we have developed our machine learning model in notebooks, we want to deploy it as a service. The purpose is to allow data science exploration to easily transition into deployed services and applications on the OpenShift platform.  After saving this project to git, it can be built on the OpenShift platform to serve models.\n",
    "\n",
    "\n",
    "There are a lot of files in this folder. We will only need to edit the noteboks, but here's insight into what each of these files do: \n",
    "\n",
    "### Project Organization\n",
    "```\n",
    ".\n",
    "├── README.md\n",
    "├── LICENSE\n",
    "├── requirements.txt        <- Used to install packages for s2i application\n",
    "├── 0_start_here.ipynb      <- Instructional notebook\n",
    "├── 1_run_flask.ipynb       <- Notebook for running flask locally to test\n",
    "├── 2_test_flask.ipynb      <- Notebook for testing flask requests\n",
    "├── .gitignore              <- standard python gitignore\n",
    "├── .s2i                    <- hidden folder for advanced s2i configuration\n",
    "│   └── environment         <- s2i environment settings\n",
    "├── gunicorn_config.py      <- configuration for gunicorn when run in OpenShift\n",
    "├── prediction.py           <- the predict function called from Flask\n",
    "└── wsgi.py                 <- basic Flask application\n",
    "```\n",
    "\n",
    "We will use a source to image build, also known as s2i, to deploy the model service, but first let's practice running the service in a notebook: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "id": "KUu4vOt5zI9d"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment\n",
    "\n",
    "Experiment with data and create your prediction function.  Create any serialized models needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudpickle as cp\n",
    "import pandas as pd\n",
    "\n",
    "pipeline = cp.load(open('pipeline.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(args_dict):\n",
    "\n",
    "    d = {'timestamp':0, 'label':0, 'user_id': args_dict.get('user_id'), 'amount': args_dict.get('amount'), 'merchant_id': args_dict.get('merchant_id'), 'trans_type': args_dict.get('trans_type'), 'foreign': args_dict.get('foreign'), 'interarrival': args_dict.get('interarrival')}\n",
    "    \n",
    "    df = pd.DataFrame(d, index=[0])\n",
    "    prediction = pipeline.predict(df)[0]\n",
    "\n",
    "    return {'prediction': prediction}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_req = {\"user_id\": 1698, \"amount\": 7915, \"merchant_id\": 22.37, \"trans_type\": \"contactless\", \"foreign\": \"False\", \"interarrival\": 9609}\n",
    "\n",
    "predict(my_req)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Predict Function\n",
    "\n",
    "Now that we are certain our prediction function is working, we can go ahead and add it to the prediction.py file. We've already done this for you, but go take a look and make sure you see what's happening. \n",
    "\n",
    "Also, make sure `requirements.txt` is updated with any additional packages you've used and need for prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Predict Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prediction import predict\n",
    "\n",
    "\n",
    "my_req = {\"user_id\": 1698, \"amount\": 7915, \"merchant_id\": 22.37, \"trans_type\": \"contactless\", \"foreign\": \"False\", \"interarrival\": 9609}\n",
    "\n",
    "predict(my_req)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try to get a prediction of fraud\n",
    "\n",
    "Now, try it again, but this time, change the values until the prediction returns **fraud** instead of **legitimate**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_req = {\"user_id\": 9999, \n",
    "             \"amount\": 9999, \n",
    "             \"merchant_id\": 99999, \n",
    "             \"trans_type\": \"contactless\", \n",
    "             \"foreign\": \"False\", \n",
    "             \"interarrival\": 1}\n",
    "\n",
    "predict(other_req)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Object detection",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
