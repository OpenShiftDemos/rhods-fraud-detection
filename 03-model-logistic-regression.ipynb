{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will train a [Logistic Regression model](https://en.wikipedia.org/wiki/Logistic_regression) to distinguish between legitimate and fraudulent transactions. \n",
    "\n",
    "Logistic Regression is a classic statistical technique used for binary classification. Here the binary variable we are predicting is 'legitimate' or 'not legitimate' (i.e. fraudulent).\n",
    "\n",
    "We begin by loading in our generated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_parquet(\"fraud-cleaned-sample.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to split our data set into two. One part will be used for training the model, and the other will be a testing set we can use to evaluate the model we train. We're dealing with time-series data, so we'll split the data set based on time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = df['timestamp'].min()\n",
    "last = df['timestamp'].max()\n",
    "cutoff = first + ((last - first) * 0.7)\n",
    "\n",
    "train = df[df['timestamp'] <= cutoff].copy()\n",
    "test = df[df['timestamp'] > cutoff]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also load in the feature engineering pipeline stage which we developed in [notebook 2](02-feature-engineering.ipynb). The model takes the feature vectors as input, rather than the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudpickle as cp\n",
    "feature_pipeline = cp.load(open('feat_pipeline.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('feature_extraction',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('interarrival_scaler',\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('median_imputer',\n",
       "                                                                   SimpleImputer(add_indicator=False,\n",
       "                                                                                 copy=True,\n",
       "                                                                                 fill_value=None,\n",
       "                                                                                 missing_values=nan,\n",
       "                                                                                 strategy='median',\n",
       "                                                                                 verbose=0)),\n",
       "                                                                  ('interarrival_...\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('dictify',\n",
       "                                                                   FunctionTransformer(accept_sparse=True,\n",
       "                                                                                       check_inverse=True,\n",
       "                                                                                       func=<function amap at 0x7fb55b6c8af0>,\n",
       "                                                                                       inv_kw_args=None,\n",
       "                                                                                       inverse_func=None,\n",
       "                                                                                       kw_args=None,\n",
       "                                                                                       validate=False)),\n",
       "                                                                  ('hasher',\n",
       "                                                                   FeatureHasher(alternate_sign=True,\n",
       "                                                                                 dtype=<class 'numpy.float64'>,\n",
       "                                                                                 input_type='dict',\n",
       "                                                                                 n_features=256))],\n",
       "                                                           verbose=False),\n",
       "                                                  'merchant_id')],\n",
       "                                   verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing with Imbalanced Classes\n",
    "\n",
    "When the training data set contains unequal representation from each of your classes we say we are dealing with 'imbalanced classes'. In our data set fewer than 2% of the samples are fraudulent, and the remaining 98% are legitimate. Thus we have imbalanced classes. \n",
    "\n",
    "This causes problems for a few reasons:\n",
    "1. A model which classifies all transactions as 'legitimate' would be correct 98% of the time. This high accuracy can trick you into thinking that your model is working well, despite it just returning 'legitimate' for every sample it sees. \n",
    "2. Even if your model tries to learn patterns in the data, it may struggle to learn from the 'fraudulent' data since there simply isn't enough of it.\n",
    "\n",
    "\n",
    "There are a few approaches we could take to tackle the problem, and today we will use two of them: \n",
    "1. We will use metrics which are more informative than simply counting how often the model makes a correct prediction. \n",
    "2. We will weight the samples by the inverse of the frequency of their label within the data set. These weights will be passed into the logistic regression model, and used to ensure that the model is penalised proportionally to this weight for making a misclassification for each class when it is training. \n",
    "\n",
    "\n",
    "In this next cell we compute these weights for each of the data labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_frequency = train[train[\"label\"] == \"fraud\"][\"timestamp\"].count() / train[\"timestamp\"].count()\n",
    "train.loc[train[\"label\"] == \"legitimate\", \"weights\"] = fraud_frequency\n",
    "train.loc[train[\"label\"] == \"fraud\", \"weights\"] = (1 - fraud_frequency)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now ready to train our Logistic Regression model. The model is trained on the feature vectors (generated using our `feature_pipeline` from the previous notebook) and we pass the class weights we computed above as a model parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(max_iter=500)\n",
    "\n",
    "svecs = feature_pipeline.fit_transform(train)\n",
    "lr.fit(svecs, train[\"label\"], sample_weight=train[\"weights\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to validate our model to check how well it performs on data it wasn't trained on. We use the model we just trained to make predictions for the data in our test set, and compare those predictions to the truth. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       fraud       0.16      0.91      0.27     14375\n",
      "  legitimate       1.00      0.90      0.95    737609\n",
      "\n",
      "    accuracy                           0.90    751984\n",
      "   macro avg       0.58      0.91      0.61    751984\n",
      "weighted avg       0.98      0.90      0.94    751984\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predictions = lr.predict(feature_pipeline.fit_transform(test))\n",
    "print(classification_report(test.label.values, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The report shows that the model is performing okay, but is much better at identifying legitimate transactions than fraudulent ones. \n",
    "\n",
    "We can visualise the accuracy of classifications in a binary confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mlworkflows'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-d4684af7273c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmlworkflows\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mchart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mlworkflows'"
     ]
    }
   ],
   "source": [
    "##from mlworkflows import plot\n",
    "##df, chart = plot.binary_confusion_matrix(test[\"label\"], predictions)\n",
    "##chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viewing the raw counts, as well as the proportions of correctly and incorrectly classified items, emphasises that the model often misclassifies 'fraudulent' transactions as 'legitimate'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>label</th>\n",
       "      <th>user_id</th>\n",
       "      <th>amount</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>trans_type</th>\n",
       "      <th>foreign</th>\n",
       "      <th>interarrival</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44905449</th>\n",
       "      <td>1622396622</td>\n",
       "      <td>legitimate</td>\n",
       "      <td>8975</td>\n",
       "      <td>24.920000</td>\n",
       "      <td>12348</td>\n",
       "      <td>chip_and_pin</td>\n",
       "      <td>False</td>\n",
       "      <td>6533.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17805936</th>\n",
       "      <td>1614921076</td>\n",
       "      <td>legitimate</td>\n",
       "      <td>3565</td>\n",
       "      <td>28.090000</td>\n",
       "      <td>12922</td>\n",
       "      <td>chip_and_pin</td>\n",
       "      <td>False</td>\n",
       "      <td>6433.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8819718</th>\n",
       "      <td>1613602539</td>\n",
       "      <td>legitimate</td>\n",
       "      <td>1765</td>\n",
       "      <td>8.880000</td>\n",
       "      <td>15416</td>\n",
       "      <td>contactless</td>\n",
       "      <td>False</td>\n",
       "      <td>8318.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5773423</th>\n",
       "      <td>1618232403</td>\n",
       "      <td>legitimate</td>\n",
       "      <td>1158</td>\n",
       "      <td>6.270000</td>\n",
       "      <td>14243</td>\n",
       "      <td>online</td>\n",
       "      <td>True</td>\n",
       "      <td>6674.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8496336</th>\n",
       "      <td>1638049937</td>\n",
       "      <td>legitimate</td>\n",
       "      <td>1698</td>\n",
       "      <td>22.379999</td>\n",
       "      <td>7915</td>\n",
       "      <td>contactless</td>\n",
       "      <td>False</td>\n",
       "      <td>9609.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41838350</th>\n",
       "      <td>1602623787</td>\n",
       "      <td>legitimate</td>\n",
       "      <td>8366</td>\n",
       "      <td>5.110000</td>\n",
       "      <td>3793</td>\n",
       "      <td>chip_and_pin</td>\n",
       "      <td>False</td>\n",
       "      <td>49999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280831</th>\n",
       "      <td>1596546511</td>\n",
       "      <td>legitimate</td>\n",
       "      <td>55</td>\n",
       "      <td>42.180000</td>\n",
       "      <td>237</td>\n",
       "      <td>swipe</td>\n",
       "      <td>False</td>\n",
       "      <td>6544.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23291970</th>\n",
       "      <td>1589385867</td>\n",
       "      <td>legitimate</td>\n",
       "      <td>4653</td>\n",
       "      <td>7.160000</td>\n",
       "      <td>990</td>\n",
       "      <td>chip_and_pin</td>\n",
       "      <td>False</td>\n",
       "      <td>44684.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18344979</th>\n",
       "      <td>1623603937</td>\n",
       "      <td>legitimate</td>\n",
       "      <td>3672</td>\n",
       "      <td>8.370000</td>\n",
       "      <td>13521</td>\n",
       "      <td>online</td>\n",
       "      <td>True</td>\n",
       "      <td>7802.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23645914</th>\n",
       "      <td>1605982237</td>\n",
       "      <td>legitimate</td>\n",
       "      <td>4724</td>\n",
       "      <td>20.660000</td>\n",
       "      <td>8026</td>\n",
       "      <td>contactless</td>\n",
       "      <td>False</td>\n",
       "      <td>7696.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500000 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           timestamp       label  user_id     amount  merchant_id  \\\n",
       "44905449  1622396622  legitimate     8975  24.920000        12348   \n",
       "17805936  1614921076  legitimate     3565  28.090000        12922   \n",
       "8819718   1613602539  legitimate     1765   8.880000        15416   \n",
       "5773423   1618232403  legitimate     1158   6.270000        14243   \n",
       "8496336   1638049937  legitimate     1698  22.379999         7915   \n",
       "...              ...         ...      ...        ...          ...   \n",
       "41838350  1602623787  legitimate     8366   5.110000         3793   \n",
       "280831    1596546511  legitimate       55  42.180000          237   \n",
       "23291970  1589385867  legitimate     4653   7.160000          990   \n",
       "18344979  1623603937  legitimate     3672   8.370000        13521   \n",
       "23645914  1605982237  legitimate     4724  20.660000         8026   \n",
       "\n",
       "            trans_type  foreign  interarrival  \n",
       "44905449  chip_and_pin    False        6533.0  \n",
       "17805936  chip_and_pin    False        6433.0  \n",
       "8819718    contactless    False        8318.0  \n",
       "5773423         online     True        6674.0  \n",
       "8496336    contactless    False        9609.0  \n",
       "...                ...      ...           ...  \n",
       "41838350  chip_and_pin    False       49999.0  \n",
       "280831           swipe    False        6544.0  \n",
       "23291970  chip_and_pin    False       44684.0  \n",
       "18344979        online     True        7802.0  \n",
       "23645914   contactless    False        7696.0  \n",
       "\n",
       "[2500000 rows x 8 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to save the model so that we can use it outside of this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp.dump(lr, open(\"lr.pkl\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
